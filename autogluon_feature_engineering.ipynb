{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "install",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7377a870-779b-4150-ec83-5c95b7e3fcd9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting autogluon\n",
            "  Downloading autogluon-1.4.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting autogluon.core==1.4.0 (from autogluon.core[all]==1.4.0->autogluon)\n",
            "  Downloading autogluon.core-1.4.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting autogluon.features==1.4.0 (from autogluon)\n",
            "  Downloading autogluon.features-1.4.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting autogluon.tabular==1.4.0 (from autogluon.tabular[all]==1.4.0->autogluon)\n",
            "  Downloading autogluon.tabular-1.4.0-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting autogluon.multimodal==1.4.0 (from autogluon)\n",
            "  Downloading autogluon.multimodal-1.4.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting autogluon.timeseries==1.4.0 (from autogluon.timeseries[all]==1.4.0->autogluon)\n",
            "  Downloading autogluon.timeseries-1.4.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: numpy<2.4.0,>=1.25.0 in /usr/local/lib/python3.12/dist-packages (from autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (2.0.2)\n",
            "Requirement already satisfied: scipy<1.17,>=1.5.4 in /usr/local/lib/python3.12/dist-packages (from autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (1.16.2)\n",
            "Requirement already satisfied: scikit-learn<1.8.0,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (1.6.1)\n",
            "Requirement already satisfied: networkx<4,>=3.0 in /usr/local/lib/python3.12/dist-packages (from autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (3.5)\n",
            "Requirement already satisfied: pandas<2.4.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (2.2.2)\n",
            "Requirement already satisfied: tqdm<5,>=4.38 in /usr/local/lib/python3.12/dist-packages (from autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (4.67.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (2.32.4)\n",
            "Requirement already satisfied: matplotlib<3.11,>=3.7.0 in /usr/local/lib/python3.12/dist-packages (from autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (3.10.0)\n",
            "Collecting boto3<2,>=1.10 (from autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon)\n",
            "  Downloading boto3-1.40.59-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting autogluon.common==1.4.0 (from autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon)\n",
            "  Downloading autogluon.common-1.4.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: hyperopt<0.2.8,>=0.2.7 in /usr/local/lib/python3.12/dist-packages (from autogluon.core[all]==1.4.0->autogluon) (0.2.7)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from autogluon.core[all]==1.4.0->autogluon) (18.1.0)\n",
            "Collecting ray<2.45,>=2.10.0 (from ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon)\n",
            "  Downloading ray-2.44.1-cp312-cp312-manylinux2014_x86_64.whl.metadata (19 kB)\n",
            "Requirement already satisfied: Pillow<12,>=10.0.1 in /usr/local/lib/python3.12/dist-packages (from autogluon.multimodal==1.4.0->autogluon) (11.3.0)\n",
            "Collecting torch<2.8,>=2.2 (from autogluon.multimodal==1.4.0->autogluon)\n",
            "  Downloading torch-2.7.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (29 kB)\n",
            "Collecting lightning<2.8,>=2.2 (from autogluon.multimodal==1.4.0->autogluon)\n",
            "  Downloading lightning-2.5.5-py3-none-any.whl.metadata (39 kB)\n",
            "Collecting transformers<4.50,>=4.38.0 (from transformers[sentencepiece]<4.50,>=4.38.0->autogluon.multimodal==1.4.0->autogluon)\n",
            "  Downloading transformers-4.49.0-py3-none-any.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: accelerate<2.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from autogluon.multimodal==1.4.0->autogluon) (1.11.0)\n",
            "Requirement already satisfied: fsspec<=2025.3 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3->autogluon.multimodal==1.4.0->autogluon) (2025.3.0)\n",
            "Collecting jsonschema<4.24,>=4.18 (from autogluon.multimodal==1.4.0->autogluon)\n",
            "  Downloading jsonschema-4.23.0-py3-none-any.whl.metadata (7.9 kB)\n",
            "Collecting seqeval<1.3.0,>=1.2.2 (from autogluon.multimodal==1.4.0->autogluon)\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting evaluate<0.5.0,>=0.4.0 (from autogluon.multimodal==1.4.0->autogluon)\n",
            "  Downloading evaluate-0.4.6-py3-none-any.whl.metadata (9.5 kB)\n",
            "Collecting timm<1.0.7,>=0.9.5 (from autogluon.multimodal==1.4.0->autogluon)\n",
            "  Downloading timm-1.0.3-py3-none-any.whl.metadata (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision<0.23.0,>=0.16.0 (from autogluon.multimodal==1.4.0->autogluon)\n",
            "  Downloading torchvision-0.22.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: scikit-image<0.26.0,>=0.19.1 in /usr/local/lib/python3.12/dist-packages (from autogluon.multimodal==1.4.0->autogluon) (0.25.2)\n",
            "Requirement already satisfied: text-unidecode<1.4,>=1.3 in /usr/local/lib/python3.12/dist-packages (from autogluon.multimodal==1.4.0->autogluon) (1.3)\n",
            "Collecting torchmetrics<1.8,>=1.2.0 (from autogluon.multimodal==1.4.0->autogluon)\n",
            "  Downloading torchmetrics-1.7.4-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: omegaconf<2.4.0,>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from autogluon.multimodal==1.4.0->autogluon) (2.3.0)\n",
            "Collecting pytorch-metric-learning<2.9,>=1.3.0 (from autogluon.multimodal==1.4.0->autogluon)\n",
            "  Downloading pytorch_metric_learning-2.8.1-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting nlpaug<1.2.0,>=1.1.10 (from autogluon.multimodal==1.4.0->autogluon)\n",
            "  Downloading nlpaug-1.1.11-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: nltk<3.10,>=3.4.5 in /usr/local/lib/python3.12/dist-packages (from autogluon.multimodal==1.4.0->autogluon) (3.9.1)\n",
            "Collecting openmim<0.4.0,>=0.3.7 (from autogluon.multimodal==1.4.0->autogluon)\n",
            "  Downloading openmim-0.3.9-py2.py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: defusedxml<0.7.2,>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from autogluon.multimodal==1.4.0->autogluon) (0.7.1)\n",
            "Requirement already satisfied: jinja2<3.2,>=3.0.3 in /usr/local/lib/python3.12/dist-packages (from autogluon.multimodal==1.4.0->autogluon) (3.1.6)\n",
            "Requirement already satisfied: tensorboard<3,>=2.9 in /usr/local/lib/python3.12/dist-packages (from autogluon.multimodal==1.4.0->autogluon) (2.19.0)\n",
            "Collecting pytesseract<0.4,>=0.3.9 (from autogluon.multimodal==1.4.0->autogluon)\n",
            "  Downloading pytesseract-0.3.13-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting nvidia-ml-py3<8.0,>=7.352.0 (from autogluon.multimodal==1.4.0->autogluon)\n",
            "  Downloading nvidia-ml-py3-7.352.0.tar.gz (19 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pdf2image<1.19,>=1.17.0 (from autogluon.multimodal==1.4.0->autogluon)\n",
            "  Downloading pdf2image-1.17.0-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting catboost<1.3,>=1.2 (from autogluon.tabular[all]==1.4.0->autogluon)\n",
            "  Downloading catboost-1.2.8-cp312-cp312-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: fastai<2.9,>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from autogluon.tabular[all]==1.4.0->autogluon) (2.8.4)\n",
            "Collecting loguru (from autogluon.tabular[all]==1.4.0->autogluon)\n",
            "  Downloading loguru-0.7.3-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: lightgbm<4.7,>=4.0 in /usr/local/lib/python3.12/dist-packages (from autogluon.tabular[all]==1.4.0->autogluon) (4.6.0)\n",
            "Collecting einx (from autogluon.tabular[all]==1.4.0->autogluon)\n",
            "  Downloading einx-0.3.0-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting xgboost<3.1,>=2.0 (from autogluon.tabular[all]==1.4.0->autogluon)\n",
            "  Downloading xgboost-3.0.5-py3-none-manylinux_2_28_x86_64.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: spacy<3.9 in /usr/local/lib/python3.12/dist-packages (from autogluon.tabular[all]==1.4.0->autogluon) (3.8.7)\n",
            "Requirement already satisfied: huggingface-hub[torch] in /usr/local/lib/python3.12/dist-packages (from autogluon.tabular[all]==1.4.0->autogluon) (0.35.3)\n",
            "Requirement already satisfied: joblib<1.7,>=1.2 in /usr/local/lib/python3.12/dist-packages (from autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon) (1.5.2)\n",
            "Collecting pytorch-lightning (from autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon)\n",
            "  Downloading pytorch_lightning-2.5.5-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting gluonts<0.17,>=0.15.0 (from autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon)\n",
            "  Downloading gluonts-0.16.2-py3-none-any.whl.metadata (9.8 kB)\n",
            "Collecting statsforecast<2.0.2,>=1.7.0 (from autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon)\n",
            "  Downloading statsforecast-2.0.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (29 kB)\n",
            "Collecting mlforecast<0.15.0,>=0.14.0 (from autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon)\n",
            "  Downloading mlforecast-0.14.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting utilsforecast<0.2.12,>=0.2.3 (from autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon)\n",
            "  Downloading utilsforecast-0.2.11-py3-none-any.whl.metadata (7.7 kB)\n",
            "Collecting coreforecast<0.0.17,>=0.0.12 (from autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon)\n",
            "  Downloading coreforecast-0.0.16-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.7 kB)\n",
            "Collecting fugue>=0.9.0 (from autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon)\n",
            "  Downloading fugue-0.9.1-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: orjson~=3.9 in /usr/local/lib/python3.12/dist-packages (from autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon) (3.11.3)\n",
            "Requirement already satisfied: psutil<7.1.0,>=5.7.3 in /usr/local/lib/python3.12/dist-packages (from autogluon.common==1.4.0->autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (5.9.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from accelerate<2.0,>=0.34.0->autogluon.multimodal==1.4.0->autogluon) (25.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from accelerate<2.0,>=0.34.0->autogluon.multimodal==1.4.0->autogluon) (6.0.3)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from accelerate<2.0,>=0.34.0->autogluon.multimodal==1.4.0->autogluon) (0.6.2)\n",
            "Collecting botocore<1.41.0,>=1.40.59 (from boto3<2,>=1.10->autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon)\n",
            "  Downloading botocore-1.40.59-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from boto3<2,>=1.10->autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting s3transfer<0.15.0,>=0.14.0 (from boto3<2,>=1.10->autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon)\n",
            "  Downloading s3transfer-0.14.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.12/dist-packages (from catboost<1.3,>=1.2->autogluon.tabular[all]==1.4.0->autogluon) (0.21)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.12/dist-packages (from catboost<1.3,>=1.2->autogluon.tabular[all]==1.4.0->autogluon) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from catboost<1.3,>=1.2->autogluon.tabular[all]==1.4.0->autogluon) (1.17.0)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.4.0->autogluon) (4.0.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.12/dist-packages (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.4.0->autogluon) (0.3.8)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.4.0->autogluon) (3.6.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.12/dist-packages (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.4.0->autogluon) (0.70.16)\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.12/dist-packages (from fastai<2.9,>=2.3.1->autogluon.tabular[all]==1.4.0->autogluon) (24.1.2)\n",
            "Requirement already satisfied: fastdownload<2,>=0.0.5 in /usr/local/lib/python3.12/dist-packages (from fastai<2.9,>=2.3.1->autogluon.tabular[all]==1.4.0->autogluon) (0.0.7)\n",
            "Requirement already satisfied: fastcore<1.9,>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from fastai<2.9,>=2.3.1->autogluon.tabular[all]==1.4.0->autogluon) (1.8.13)\n",
            "Requirement already satisfied: fasttransform>=0.0.2 in /usr/local/lib/python3.12/dist-packages (from fastai<2.9,>=2.3.1->autogluon.tabular[all]==1.4.0->autogluon) (0.0.2)\n",
            "Requirement already satisfied: fastprogress>=0.2.4 in /usr/local/lib/python3.12/dist-packages (from fastai<2.9,>=2.3.1->autogluon.tabular[all]==1.4.0->autogluon) (1.0.3)\n",
            "Requirement already satisfied: plum-dispatch in /usr/local/lib/python3.12/dist-packages (from fastai<2.9,>=2.3.1->autogluon.tabular[all]==1.4.0->autogluon) (2.5.8)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.12/dist-packages (from fastai<2.9,>=2.3.1->autogluon.tabular[all]==1.4.0->autogluon) (3.1.1)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3->autogluon.multimodal==1.4.0->autogluon) (3.13.1)\n",
            "Collecting triad>=0.9.7 (from fugue>=0.9.0->autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon)\n",
            "  Downloading triad-0.9.8-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting adagio>=0.2.4 (from fugue>=0.9.0->autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon)\n",
            "  Downloading adagio-0.2.6-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: pydantic<3,>=1.7 in /usr/local/lib/python3.12/dist-packages (from gluonts<0.17,>=0.15.0->autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon) (2.11.10)\n",
            "Requirement already satisfied: toolz~=0.10 in /usr/local/lib/python3.12/dist-packages (from gluonts<0.17,>=0.15.0->autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon) (0.12.1)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.12/dist-packages (from gluonts<0.17,>=0.15.0->autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon) (4.15.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.12/dist-packages (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==1.4.0->autogluon) (1.0.0)\n",
            "Requirement already satisfied: py4j in /usr/local/lib/python3.12/dist-packages (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==1.4.0->autogluon) (0.10.9.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2<3.2,>=3.0.3->autogluon.multimodal==1.4.0->autogluon) (3.0.3)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema<4.24,>=4.18->autogluon.multimodal==1.4.0->autogluon) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema<4.24,>=4.18->autogluon.multimodal==1.4.0->autogluon) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema<4.24,>=4.18->autogluon.multimodal==1.4.0->autogluon) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema<4.24,>=4.18->autogluon.multimodal==1.4.0->autogluon) (0.27.1)\n",
            "Collecting lightning-utilities<2.0,>=0.10.0 (from lightning<2.8,>=2.2->autogluon.multimodal==1.4.0->autogluon)\n",
            "  Downloading lightning_utilities-0.15.2-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (1.4.9)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (2.9.0.post0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.12/dist-packages (from mlforecast<0.15.0,>=0.14.0->autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon) (0.60.0)\n",
            "Collecting optuna (from mlforecast<0.15.0,>=0.14.0->autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon)\n",
            "  Downloading optuna-4.5.0-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting window-ops (from mlforecast<0.15.0,>=0.14.0->autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon)\n",
            "  Downloading window_ops-0.0.15-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: gdown>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==1.4.0->autogluon) (5.2.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk<3.10,>=3.4.5->autogluon.multimodal==1.4.0->autogluon) (8.3.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk<3.10,>=3.4.5->autogluon.multimodal==1.4.0->autogluon) (2024.11.6)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.12/dist-packages (from omegaconf<2.4.0,>=2.1.1->autogluon.multimodal==1.4.0->autogluon) (4.9.3)\n",
            "Collecting colorama (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.4.0->autogluon)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Collecting model-index (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.4.0->autogluon)\n",
            "  Downloading model_index-0.1.11-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting opendatalab (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.4.0->autogluon)\n",
            "  Downloading opendatalab-0.0.10-py3-none-any.whl.metadata (6.4 kB)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.4.0->autogluon) (13.9.4)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.12/dist-packages (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.4.0->autogluon) (0.9.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<2.4.0,>=2.0.0->autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<2.4.0,>=2.0.0->autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (2025.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from ray<2.45,>=2.10.0->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon) (3.20.0)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from ray<2.45,>=2.10.0->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon) (1.1.2)\n",
            "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /usr/local/lib/python3.12/dist-packages (from ray<2.45,>=2.10.0->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon) (5.29.5)\n",
            "Requirement already satisfied: aiosignal in /usr/local/lib/python3.12/dist-packages (from ray<2.45,>=2.10.0->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon) (1.4.0)\n",
            "Requirement already satisfied: frozenlist in /usr/local/lib/python3.12/dist-packages (from ray<2.45,>=2.10.0->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon) (1.8.0)\n",
            "Collecting aiohttp_cors (from ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon)\n",
            "  Downloading aiohttp_cors-0.8.1-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting colorful (from ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon)\n",
            "  Downloading colorful-0.5.7-py2.py3-none-any.whl.metadata (16 kB)\n",
            "Collecting py-spy>=0.4.0 (from ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon)\n",
            "  Downloading py_spy-0.4.1-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl.metadata (510 bytes)\n",
            "Requirement already satisfied: grpcio>=1.42.0 in /usr/local/lib/python3.12/dist-packages (from ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon) (1.75.1)\n",
            "Collecting opencensus (from ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon)\n",
            "  Downloading opencensus-0.11.4-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: prometheus_client>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon) (0.23.1)\n",
            "Requirement already satisfied: smart_open in /usr/local/lib/python3.12/dist-packages (from ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon) (7.4.0)\n",
            "Collecting virtualenv!=20.21.1,>=20.0.24 (from ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon)\n",
            "  Downloading virtualenv-20.35.3-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting tensorboardX>=1.9 (from ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon)\n",
            "  Downloading tensorboardx-2.6.4-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (2025.10.5)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.12/dist-packages (from scikit-image<0.26.0,>=0.19.1->autogluon.multimodal==1.4.0->autogluon) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.12/dist-packages (from scikit-image<0.26.0,>=0.19.1->autogluon.multimodal==1.4.0->autogluon) (2025.10.16)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.12/dist-packages (from scikit-image<0.26.0,>=0.19.1->autogluon.multimodal==1.4.0->autogluon) (0.4)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn<1.8.0,>=1.4.0->autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (3.6.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.12/dist-packages (from spacy<3.9->autogluon.tabular[all]==1.4.0->autogluon) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from spacy<3.9->autogluon.tabular[all]==1.4.0->autogluon) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.12/dist-packages (from spacy<3.9->autogluon.tabular[all]==1.4.0->autogluon) (1.0.13)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy<3.9->autogluon.tabular[all]==1.4.0->autogluon) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy<3.9->autogluon.tabular[all]==1.4.0->autogluon) (3.0.10)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.12/dist-packages (from spacy<3.9->autogluon.tabular[all]==1.4.0->autogluon) (8.3.6)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.12/dist-packages (from spacy<3.9->autogluon.tabular[all]==1.4.0->autogluon) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.12/dist-packages (from spacy<3.9->autogluon.tabular[all]==1.4.0->autogluon) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.12/dist-packages (from spacy<3.9->autogluon.tabular[all]==1.4.0->autogluon) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.12/dist-packages (from spacy<3.9->autogluon.tabular[all]==1.4.0->autogluon) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from spacy<3.9->autogluon.tabular[all]==1.4.0->autogluon) (0.20.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from spacy<3.9->autogluon.tabular[all]==1.4.0->autogluon) (75.2.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.12/dist-packages (from spacy<3.9->autogluon.tabular[all]==1.4.0->autogluon) (3.5.0)\n",
            "Requirement already satisfied: statsmodels>=0.13.2 in /usr/local/lib/python3.12/dist-packages (from statsforecast<2.0.2,>=1.7.0->autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon) (0.14.5)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.12/dist-packages (from tensorboard<3,>=2.9->autogluon.multimodal==1.4.0->autogluon) (1.4.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard<3,>=2.9->autogluon.multimodal==1.4.0->autogluon) (3.9)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard<3,>=2.9->autogluon.multimodal==1.4.0->autogluon) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard<3,>=2.9->autogluon.multimodal==1.4.0->autogluon) (3.1.3)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch<2.8,>=2.2->autogluon.multimodal==1.4.0->autogluon) (1.13.3)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<2.8,>=2.2->autogluon.multimodal==1.4.0->autogluon) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<2.8,>=2.2->autogluon.multimodal==1.4.0->autogluon) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch<2.8,>=2.2->autogluon.multimodal==1.4.0->autogluon) (12.6.80)\n",
            "Collecting nvidia-cudnn-cu12==9.5.1.17 (from torch<2.8,>=2.2->autogluon.multimodal==1.4.0->autogluon)\n",
            "  Downloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch<2.8,>=2.2->autogluon.multimodal==1.4.0->autogluon) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch<2.8,>=2.2->autogluon.multimodal==1.4.0->autogluon) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch<2.8,>=2.2->autogluon.multimodal==1.4.0->autogluon) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch<2.8,>=2.2->autogluon.multimodal==1.4.0->autogluon) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch<2.8,>=2.2->autogluon.multimodal==1.4.0->autogluon) (12.5.4.2)\n",
            "Collecting nvidia-cusparselt-cu12==0.6.3 (from torch<2.8,>=2.2->autogluon.multimodal==1.4.0->autogluon)\n",
            "  Downloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Collecting nvidia-nccl-cu12==2.26.2 (from torch<2.8,>=2.2->autogluon.multimodal==1.4.0->autogluon)\n",
            "  Downloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<2.8,>=2.2->autogluon.multimodal==1.4.0->autogluon) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch<2.8,>=2.2->autogluon.multimodal==1.4.0->autogluon) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch<2.8,>=2.2->autogluon.multimodal==1.4.0->autogluon) (1.11.1.6)\n",
            "Collecting triton==3.3.1 (from torch<2.8,>=2.2->autogluon.multimodal==1.4.0->autogluon)\n",
            "  Downloading triton-3.3.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting tokenizers<0.22,>=0.21 (from transformers<4.50,>=4.38.0->transformers[sentencepiece]<4.50,>=4.38.0->autogluon.multimodal==1.4.0->autogluon)\n",
            "  Downloading tokenizers-0.21.4-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /usr/local/lib/python3.12/dist-packages (from transformers[sentencepiece]<4.50,>=4.38.0->autogluon.multimodal==1.4.0->autogluon) (0.2.1)\n",
            "Requirement already satisfied: frozendict in /usr/local/lib/python3.12/dist-packages (from einx->autogluon.tabular[all]==1.4.0->autogluon) (2.4.6)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub[torch]; extra == \"all\"->autogluon.tabular[all]==1.4.0->autogluon) (1.1.10)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3->autogluon.multimodal==1.4.0->autogluon) (2.6.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3->autogluon.multimodal==1.4.0->autogluon) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3->autogluon.multimodal==1.4.0->autogluon) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3->autogluon.multimodal==1.4.0->autogluon) (1.22.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from gdown>=4.0.0->nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==1.4.0->autogluon) (4.13.5)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.12/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.9->autogluon.tabular[all]==1.4.0->autogluon) (1.3.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba->mlforecast<0.15.0,>=0.14.0->autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon) (0.43.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.7->gluonts<0.17,>=0.15.0->autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.7->gluonts<0.17,>=0.15.0->autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.7->gluonts<0.17,>=0.15.0->autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon) (0.4.2)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.12/dist-packages (from statsmodels>=0.13.2->statsforecast<2.0.2,>=1.7.0->autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon) (1.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch<2.8,>=2.2->autogluon.multimodal==1.4.0->autogluon) (1.3.0)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy<3.9->autogluon.tabular[all]==1.4.0->autogluon) (1.3.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy<3.9->autogluon.tabular[all]==1.4.0->autogluon) (0.1.5)\n",
            "Collecting fs (from triad>=0.9.7->fugue>=0.9.0->autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon)\n",
            "  Downloading fs-2.4.16-py2.py3-none-any.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.9->autogluon.tabular[all]==1.4.0->autogluon) (1.5.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.4.0->autogluon) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.4.0->autogluon) (2.19.2)\n",
            "Collecting distlib<1,>=0.3.7 (from virtualenv!=20.21.1,>=20.0.24->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon)\n",
            "  Downloading distlib-0.4.0-py2.py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: platformdirs<5,>=3.9.1 in /usr/local/lib/python3.12/dist-packages (from virtualenv!=20.21.1,>=20.0.24->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon) (4.5.0)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.9->autogluon.tabular[all]==1.4.0->autogluon) (0.23.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart_open->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon) (2.0.0)\n",
            "Collecting ordered-set (from model-index->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.4.0->autogluon)\n",
            "  Downloading ordered_set-4.1.0-py3-none-any.whl.metadata (5.3 kB)\n",
            "Collecting opencensus-context>=0.1.3 (from opencensus->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon)\n",
            "  Downloading opencensus_context-0.1.3-py2.py3-none-any.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: google-api-core<3.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from opencensus->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon) (2.26.0)\n",
            "Collecting pycryptodome (from opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.4.0->autogluon)\n",
            "  Downloading pycryptodome-3.23.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
            "Collecting openxlab (from opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.4.0->autogluon)\n",
            "  Downloading openxlab-0.1.3-py3-none-any.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from optuna->mlforecast<0.15.0,>=0.14.0->autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon) (1.17.0)\n",
            "Collecting colorlog (from optuna->mlforecast<0.15.0,>=0.14.0->autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon)\n",
            "  Downloading colorlog-6.10.1-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.12/dist-packages (from optuna->mlforecast<0.15.0,>=0.14.0->autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon) (2.0.44)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.12/dist-packages (from plotly->catboost<1.3,>=1.2->autogluon.tabular[all]==1.4.0->autogluon) (8.5.0)\n",
            "Requirement already satisfied: beartype>=0.16.2 in /usr/local/lib/python3.12/dist-packages (from plum-dispatch->fastai<2.9,>=2.3.1->autogluon.tabular[all]==1.4.0->autogluon) (0.22.2)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna->mlforecast<0.15.0,>=0.14.0->autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon) (1.3.10)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon) (1.71.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon) (1.26.1)\n",
            "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in /usr/local/lib/python3.12/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon) (2.38.0)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.9->autogluon.tabular[all]==1.4.0->autogluon) (1.3.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.4.0->autogluon) (0.1.2)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy>=1.4.2->optuna->mlforecast<0.15.0,>=0.14.0->autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon) (3.2.4)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->gdown>=4.0.0->nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==1.4.0->autogluon) (2.8)\n",
            "Collecting appdirs~=1.4.3 (from fs->triad>=0.9.7->fugue>=0.9.0->autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon)\n",
            "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting filelock (from ray<2.45,>=2.10.0->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon)\n",
            "  Downloading filelock-3.14.0-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting oss2~=2.17.0 (from openxlab->opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.4.0->autogluon)\n",
            "  Downloading oss2-2.17.0.tar.gz (259 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m259.5/259.5 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting packaging>=20.0 (from accelerate<2.0,>=0.34.0->autogluon.multimodal==1.4.0->autogluon)\n",
            "  Downloading packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting pytz>=2020.1 (from pandas<2.4.0,>=2.0.0->autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon)\n",
            "  Downloading pytz-2023.4-py2.py3-none-any.whl.metadata (22 kB)\n",
            "INFO: pip is looking at multiple versions of openxlab to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting openxlab (from opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.4.0->autogluon)\n",
            "  Downloading openxlab-0.1.2-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading openxlab-0.1.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading openxlab-0.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading openxlab-0.0.38-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading openxlab-0.0.37-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading openxlab-0.0.36-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading openxlab-0.0.35-py3-none-any.whl.metadata (3.8 kB)\n",
            "INFO: pip is still looking at multiple versions of openxlab to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading openxlab-0.0.34-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading openxlab-0.0.33-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading openxlab-0.0.32-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading openxlab-0.0.31-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading openxlab-0.0.30-py3-none-any.whl.metadata (3.8 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Downloading openxlab-0.0.29-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading openxlab-0.0.28-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading openxlab-0.0.27-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading openxlab-0.0.26-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading openxlab-0.0.25-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading openxlab-0.0.24-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading openxlab-0.0.23-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading openxlab-0.0.22-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading openxlab-0.0.21-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading openxlab-0.0.20-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading openxlab-0.0.19-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading openxlab-0.0.18-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading openxlab-0.0.17-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading openxlab-0.0.16-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading openxlab-0.0.15-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading openxlab-0.0.14-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading openxlab-0.0.13-py3-none-any.whl.metadata (4.5 kB)\n",
            "  Downloading openxlab-0.0.12-py3-none-any.whl.metadata (4.5 kB)\n",
            "  Downloading openxlab-0.0.11-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown>=4.0.0->nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==1.4.0->autogluon) (1.7.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon) (4.9.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon) (0.6.1)\n",
            "Downloading autogluon-1.4.0-py3-none-any.whl (9.8 kB)\n",
            "Downloading autogluon.core-1.4.0-py3-none-any.whl (225 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m225.1/225.1 kB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading autogluon.features-1.4.0-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.2/64.2 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading autogluon.multimodal-1.4.0-py3-none-any.whl (454 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m454.9/454.9 kB\u001b[0m \u001b[31m32.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading autogluon.tabular-1.4.0-py3-none-any.whl (487 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m487.3/487.3 kB\u001b[0m \u001b[31m45.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading autogluon.timeseries-1.4.0-py3-none-any.whl (189 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m189.7/189.7 kB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading autogluon.common-1.4.0-py3-none-any.whl (70 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.0/71.0 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading boto3-1.40.59-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.3/139.3 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading catboost-1.2.8-cp312-cp312-manylinux2014_x86_64.whl (99.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coreforecast-0.0.16-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (287 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m287.4/287.4 kB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading evaluate-0.4.6-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fugue-0.9.1-py3-none-any.whl (278 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.2/278.2 kB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gluonts-0.16.2-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m84.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonschema-4.23.0-py3-none-any.whl (88 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.5/88.5 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning-2.5.5-py3-none-any.whl (828 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m828.5/828.5 kB\u001b[0m \u001b[31m52.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mlforecast-0.14.0-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nlpaug-1.1.11-py3-none-any.whl (410 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.5/410.5 kB\u001b[0m \u001b[31m38.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openmim-0.3.9-py2.py3-none-any.whl (52 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.7/52.7 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pdf2image-1.17.0-py3-none-any.whl (11 kB)\n",
            "Downloading pytesseract-0.3.13-py3-none-any.whl (14 kB)\n",
            "Downloading pytorch_metric_learning-2.8.1-py3-none-any.whl (125 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.9/125.9 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ray-2.44.1-cp312-cp312-manylinux2014_x86_64.whl (68.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.1/68.1 MB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading statsforecast-2.0.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (353 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m353.3/353.3 kB\u001b[0m \u001b[31m36.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading timm-1.0.3-py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m104.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch-2.7.1-cp312-cp312-manylinux_2_28_x86_64.whl (821.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m821.0/821.0 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl (571.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m571.0/571.0 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl (156.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.8/156.8 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (201.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.3/201.3 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-3.3.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (155.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.7/155.7 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchmetrics-1.7.4-py3-none-any.whl (963 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m963.5/963.5 kB\u001b[0m \u001b[31m60.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchvision-0.22.1-cp312-cp312-manylinux_2_28_x86_64.whl (7.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m98.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading transformers-4.49.0-py3-none-any.whl (10.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m40.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading utilsforecast-0.2.11-py3-none-any.whl (41 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xgboost-3.0.5-py3-none-manylinux_2_28_x86_64.whl (94.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.9/94.9 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading einx-0.3.0-py3-none-any.whl (102 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.0/103.0 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading loguru-0.7.3-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.6/61.6 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytorch_lightning-2.5.5-py3-none-any.whl (832 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m832.4/832.4 kB\u001b[0m \u001b[31m59.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading adagio-0.2.6-py3-none-any.whl (19 kB)\n",
            "Downloading botocore-1.40.59-py3-none-any.whl (14.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m111.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Downloading lightning_utilities-0.15.2-py3-none-any.whl (29 kB)\n",
            "Downloading py_spy-0.4.1-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (2.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m98.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading s3transfer-0.14.0-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.7/85.7 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboardx-2.6.4-py3-none-any.whl (87 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.21.4-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m113.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triad-0.9.8-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading virtualenv-20.35.3-py3-none-any.whl (6.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m129.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiohttp_cors-0.8.1-py3-none-any.whl (25 kB)\n",
            "Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading colorful-0.5.7-py2.py3-none-any.whl (201 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.5/201.5 kB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading model_index-0.1.11-py3-none-any.whl (34 kB)\n",
            "Downloading opencensus-0.11.4-py2.py3-none-any.whl (128 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opendatalab-0.0.10-py3-none-any.whl (29 kB)\n",
            "Downloading optuna-4.5.0-py3-none-any.whl (400 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m400.9/400.9 kB\u001b[0m \u001b[31m40.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading window_ops-0.0.15-py3-none-any.whl (15 kB)\n",
            "Downloading distlib-0.4.0-py2.py3-none-any.whl (469 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m469.0/469.0 kB\u001b[0m \u001b[31m47.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opencensus_context-0.1.3-py2.py3-none-any.whl (5.1 kB)\n",
            "Downloading colorlog-6.10.1-py3-none-any.whl (11 kB)\n",
            "Downloading fs-2.4.16-py2.py3-none-any.whl (135 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.3/135.3 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openxlab-0.0.11-py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.3/55.3 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ordered_set-4.1.0-py3-none-any.whl (7.6 kB)\n",
            "Downloading pycryptodome-3.23.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m102.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
            "Building wheels for collected packages: nvidia-ml-py3, seqeval\n",
            "  Building wheel for nvidia-ml-py3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nvidia-ml-py3: filename=nvidia_ml_py3-7.352.0-py3-none-any.whl size=19172 sha256=ef909552d1ef9a90c0c6d019a7d19baaca3ff432eb2b16d13a7302342cb73a30\n",
            "  Stored in directory: /root/.cache/pip/wheels/6e/65/79/33dee66cba26e8204801916dfee7481bccfd22905ebb841fe5\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16162 sha256=31c4231dff76d10482155ce2224ec8fe0e4693aa6a344faf95fd973b1d289a0a\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/b8/73/0b2c1a76b701a677653dd79ece07cfabd7457989dbfbdcd8d7\n",
            "Successfully built nvidia-ml-py3 seqeval\n",
            "Installing collected packages: py-spy, opencensus-context, nvidia-ml-py3, nvidia-cusparselt-cu12, distlib, colorful, appdirs, virtualenv, triton, tensorboardX, pytesseract, pycryptodome, pdf2image, ordered-set, openxlab, nvidia-nccl-cu12, nvidia-cudnn-cu12, loguru, lightning-utilities, jmespath, fs, coreforecast, colorlog, colorama, xgboost, window-ops, model-index, einx, botocore, utilsforecast, triad, torch, tokenizers, seqeval, s3transfer, optuna, opendatalab, jsonschema, gluonts, catboost, aiohttp_cors, transformers, torchvision, torchmetrics, ray, pytorch-metric-learning, openmim, opencensus, nlpaug, mlforecast, boto3, adagio, timm, pytorch-lightning, fugue, evaluate, autogluon.common, statsforecast, lightning, autogluon.features, autogluon.core, autogluon.tabular, autogluon.multimodal, autogluon.timeseries, autogluon\n",
            "  Attempting uninstall: nvidia-cusparselt-cu12\n",
            "    Found existing installation: nvidia-cusparselt-cu12 0.7.1\n",
            "    Uninstalling nvidia-cusparselt-cu12-0.7.1:\n",
            "      Successfully uninstalled nvidia-cusparselt-cu12-0.7.1\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.4.0\n",
            "    Uninstalling triton-3.4.0:\n",
            "      Successfully uninstalled triton-3.4.0\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.27.3\n",
            "    Uninstalling nvidia-nccl-cu12-2.27.3:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.27.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.10.2.21\n",
            "    Uninstalling nvidia-cudnn-cu12-9.10.2.21:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.10.2.21\n",
            "  Attempting uninstall: xgboost\n",
            "    Found existing installation: xgboost 3.1.0\n",
            "    Uninstalling xgboost-3.1.0:\n",
            "      Successfully uninstalled xgboost-3.1.0\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.8.0+cu126\n",
            "    Uninstalling torch-2.8.0+cu126:\n",
            "      Successfully uninstalled torch-2.8.0+cu126\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.22.1\n",
            "    Uninstalling tokenizers-0.22.1:\n",
            "      Successfully uninstalled tokenizers-0.22.1\n",
            "  Attempting uninstall: jsonschema\n",
            "    Found existing installation: jsonschema 4.25.1\n",
            "    Uninstalling jsonschema-4.25.1:\n",
            "      Successfully uninstalled jsonschema-4.25.1\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.57.1\n",
            "    Uninstalling transformers-4.57.1:\n",
            "      Successfully uninstalled transformers-4.57.1\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.23.0+cu126\n",
            "    Uninstalling torchvision-0.23.0+cu126:\n",
            "      Successfully uninstalled torchvision-0.23.0+cu126\n",
            "  Attempting uninstall: timm\n",
            "    Found existing installation: timm 1.0.20\n",
            "    Uninstalling timm-1.0.20:\n",
            "      Successfully uninstalled timm-1.0.20\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.8.0+cu126 requires torch==2.8.0, but you have torch 2.7.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed adagio-0.2.6 aiohttp_cors-0.8.1 appdirs-1.4.4 autogluon-1.4.0 autogluon.common-1.4.0 autogluon.core-1.4.0 autogluon.features-1.4.0 autogluon.multimodal-1.4.0 autogluon.tabular-1.4.0 autogluon.timeseries-1.4.0 boto3-1.40.59 botocore-1.40.59 catboost-1.2.8 colorama-0.4.6 colorful-0.5.7 colorlog-6.10.1 coreforecast-0.0.16 distlib-0.4.0 einx-0.3.0 evaluate-0.4.6 fs-2.4.16 fugue-0.9.1 gluonts-0.16.2 jmespath-1.0.1 jsonschema-4.23.0 lightning-2.5.5 lightning-utilities-0.15.2 loguru-0.7.3 mlforecast-0.14.0 model-index-0.1.11 nlpaug-1.1.11 nvidia-cudnn-cu12-9.5.1.17 nvidia-cusparselt-cu12-0.6.3 nvidia-ml-py3-7.352.0 nvidia-nccl-cu12-2.26.2 opencensus-0.11.4 opencensus-context-0.1.3 opendatalab-0.0.10 openmim-0.3.9 openxlab-0.0.11 optuna-4.5.0 ordered-set-4.1.0 pdf2image-1.17.0 py-spy-0.4.1 pycryptodome-3.23.0 pytesseract-0.3.13 pytorch-lightning-2.5.5 pytorch-metric-learning-2.8.1 ray-2.44.1 s3transfer-0.14.0 seqeval-1.2.2 statsforecast-2.0.1 tensorboardX-2.6.4 timm-1.0.3 tokenizers-0.21.4 torch-2.7.1 torchmetrics-1.7.4 torchvision-0.22.1 transformers-4.49.0 triad-0.9.8 triton-3.3.1 utilsforecast-0.2.11 virtualenv-20.35.3 window-ops-0.0.15 xgboost-3.0.5\n"
          ]
        }
      ],
      "source": [
        "!pip install autogluon"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "import_cell",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a9a9fe0-fa40-4e15-e4ea-e90220274622"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Libraries imported successfully!\n"
          ]
        }
      ],
      "source": [
        "from autogluon.tabular import TabularDataset, TabularPredictor\n",
        "from autogluon.features.generators import AutoMLPipelineFeatureGenerator, PipelineFeatureGenerator\n",
        "from autogluon.features.generators import CategoryFeatureGenerator, IdentityFeatureGenerator\n",
        "from autogluon.common.features.types import R_INT, R_FLOAT\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "from sklearn.datasets import make_regression\n",
        "from datetime import datetime\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"✓ Libraries imported successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "create_dataset",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10a010aa-dd84-4b3e-8733-c1b0ad193fb3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "SAMPLE DATASET WITH MULTIPLE FEATURE TYPES\n",
            "======================================================================\n",
            "\n",
            "Dataset shape: (100, 5)\n",
            "\n",
            "First 10 rows:\n",
            "          A  B          C  D                E\n",
            "0 -0.545774  0 2000-01-01  y    jkl ghi jkl d\n",
            "1 -0.468674  0 2000-01-02  x   jkl ef abc ghi\n",
            "2  1.767960  0 1999-12-31  v     d ef ghi jkl\n",
            "3 -0.118771  1 2000-01-01  y      d abc ef ef\n",
            "4  0.630196  0 1999-12-31  w       d ghi ef d\n",
            "5  0.035360  0 2000-01-01  y  abc ghi jkl jkl\n",
            "6  0.602319  0 2000-01-02  v    ef abc ghi ef\n",
            "7 -0.200758  0 2000-01-01  w      ghi d d jkl\n",
            "8 -0.822467  0 2000-01-01  v      d jkl d ghi\n",
            "9 -2.060141  0 2000-01-02  y    d abc ghi ghi\n",
            "\n",
            "======================================================================\n",
            "DATA TYPES\n",
            "======================================================================\n",
            "A           float64\n",
            "B             int64\n",
            "C    datetime64[ns]\n",
            "D          category\n",
            "E            object\n",
            "dtype: object\n",
            "\n",
            "======================================================================\n",
            "BASIC STATISTICS\n",
            "======================================================================\n",
            "                A           B                    C\n",
            "count  100.000000  100.000000                  100\n",
            "mean     0.021057    0.110000  2000-01-01 00:43:12\n",
            "min     -2.434838   -2.000000  1999-12-30 00:00:00\n",
            "25%     -0.626483    0.000000  2000-01-01 00:00:00\n",
            "50%      0.025944    0.000000  2000-01-01 00:00:00\n",
            "75%      0.676074    0.000000  2000-01-01 00:00:00\n",
            "max      2.137828    2.000000  2000-01-04 00:00:00\n",
            "std      1.029086    0.617833                  NaN\n"
          ]
        }
      ],
      "source": [
        "# Generate synthetic regression data\n",
        "x, y = make_regression(n_samples=100, n_features=5, n_targets=1, random_state=1)\n",
        "\n",
        "# Create DataFrames\n",
        "dfx = pd.DataFrame(x, columns=['A', 'B', 'C', 'D', 'E'])\n",
        "dfy = pd.DataFrame(y, columns=['label'])\n",
        "\n",
        "# Column B: Convert to integer\n",
        "dfx['B'] = (dfx['B']).astype(int)\n",
        "\n",
        "# Column C: Convert to datetime\n",
        "dfx['C'] = datetime(2000, 1, 1) + pd.to_timedelta(dfx['C'].astype(int), unit='D')\n",
        "\n",
        "# Column D: Convert to categorical with labels\n",
        "dfx['D'] = pd.cut(dfx['D'] * 10, [-np.inf, -5, 0, 5, np.inf], labels=['v', 'w', 'x', 'y'])\n",
        "\n",
        "# Column E: Create random text strings\n",
        "dfx['E'] = pd.Series([\n",
        "    ' '.join(random.choice([\"abc\", \"d\", \"ef\", \"ghi\", \"jkl\"]) for i in range(4))\n",
        "    for j in range(100)\n",
        "])\n",
        "\n",
        "# Display the dataset\n",
        "print(\"=\"*70)\n",
        "print(\"SAMPLE DATASET WITH MULTIPLE FEATURE TYPES\")\n",
        "print(\"=\"*70)\n",
        "print(\"\\nDataset shape:\", dfx.shape)\n",
        "print(\"\\nFirst 10 rows:\")\n",
        "print(dfx.head(10))\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"DATA TYPES\")\n",
        "print(\"=\"*70)\n",
        "print(dfx.dtypes)\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"BASIC STATISTICS\")\n",
        "print(\"=\"*70)\n",
        "print(dfx.describe())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "auto_fe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d95ac67e-2a52-470a-8933-d09fab5a9d57"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "TRANSFORMED DATA\n",
            "======================================================================\n",
            "\n",
            "Original features: 5\n",
            "Transformed features: 16\n",
            "\n",
            "First 10 rows of transformed data:\n",
            "          A  B  D    E                   C  C.year  C.month  C.day  \\\n",
            "0 -0.545774  0  3  NaN  946684800000000000    2000        1      1   \n",
            "1 -0.468674  0  2  NaN  946771200000000000    2000        1      2   \n",
            "2  1.767960  0  0  NaN  946598400000000000    1999       12     31   \n",
            "3 -0.118771  1  3    4  946684800000000000    2000        1      1   \n",
            "4  0.630196  0  1  NaN  946598400000000000    1999       12     31   \n",
            "5  0.035360  0  3  NaN  946684800000000000    2000        1      1   \n",
            "6  0.602319  0  0  NaN  946771200000000000    2000        1      2   \n",
            "7 -0.200758  0  1  NaN  946684800000000000    2000        1      1   \n",
            "8 -0.822467  0  0  NaN  946684800000000000    2000        1      1   \n",
            "9 -2.060141  0  3    5  946771200000000000    2000        1      2   \n",
            "\n",
            "   C.dayofweek  E.char_count  E.symbol_ratio.   __nlp__.abc  __nlp__.ef  \\\n",
            "0            5             5                 2            0           0   \n",
            "1            6             6                 1            1           1   \n",
            "2            4             4                 3            0           1   \n",
            "3            5             3                 4            1           2   \n",
            "4            4             2                 5            0           1   \n",
            "5            5             7                 0            1           0   \n",
            "6            6             5                 2            1           2   \n",
            "7            5             3                 4            0           0   \n",
            "8            5             3                 4            0           0   \n",
            "9            6             5                 2            1           0   \n",
            "\n",
            "   __nlp__.ghi  __nlp__.jkl  __nlp__._total_  \n",
            "0            1            2                2  \n",
            "1            1            1                4  \n",
            "2            1            1                3  \n",
            "3            0            0                2  \n",
            "4            1            0                2  \n",
            "5            1            2                3  \n",
            "6            1            0                3  \n",
            "7            1            1                2  \n",
            "8            1            1                2  \n",
            "9            2            0                2  \n",
            "\n",
            "======================================================================\n",
            "NEW FEATURE COLUMNS\n",
            "======================================================================\n",
            "\n",
            "Columns in transformed data:\n",
            "  - A\n",
            "  - B\n",
            "  - D\n",
            "  - E\n",
            "  - C\n",
            "  - C.year\n",
            "  - C.month\n",
            "  - C.day\n",
            "  - C.dayofweek\n",
            "  - E.char_count\n",
            "  - E.symbol_ratio. \n",
            "  - __nlp__.abc\n",
            "  - __nlp__.ef\n",
            "  - __nlp__.ghi\n",
            "  - __nlp__.jkl\n",
            "  - __nlp__._total_\n"
          ]
        }
      ],
      "source": [
        "# Create the feature generator\n",
        "auto_ml_pipeline_feature_generator = AutoMLPipelineFeatureGenerator()\n",
        "\n",
        "# Transform the data\n",
        "transformed_data = auto_ml_pipeline_feature_generator.fit_transform(X=dfx)\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"TRANSFORMED DATA\")\n",
        "print(\"=\"*70)\n",
        "print(\"\\nOriginal features:\", dfx.shape[1])\n",
        "print(\"Transformed features:\", transformed_data.shape[1])\n",
        "print(\"\\nFirst 10 rows of transformed data:\")\n",
        "print(transformed_data.head(10))\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"NEW FEATURE COLUMNS\")\n",
        "print(\"=\"*70)\n",
        "print(\"\\nColumns in transformed data:\")\n",
        "for col in transformed_data.columns:\n",
        "    print(f\"  - {col}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "train_model",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ab875cb-9cc0-44d7-becd-23c607475229"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20251026_192142\"\n",
            "Verbosity: 2 (Standard Logging)\n",
            "=================== System Info ===================\n",
            "AutoGluon Version:  1.4.0\n",
            "Python Version:     3.12.12\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP Thu Oct  2 10:42:05 UTC 2025\n",
            "CPU Count:          2\n",
            "Memory Avail:       11.59 GB / 12.67 GB (91.5%)\n",
            "Disk Space Avail:   61.62 GB / 107.72 GB (57.2%)\n",
            "===================================================\n",
            "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
            "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
            "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
            "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
            "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
            "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
            "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "TRAINING MODEL WITH AUTOGLUON\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Beginning AutoGluon training ... Time limit = 60s\n",
            "AutoGluon will save models to \"/content/AutogluonModels/ag-20251026_192142\"\n",
            "Train Data Rows:    100\n",
            "Train Data Columns: 5\n",
            "Label Column:       label\n",
            "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
            "\tLabel info (max, min, mean, stddev): (186.98105511749836, -267.99365510467214, 9.38193, 71.29287)\n",
            "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
            "Problem Type:       regression\n",
            "Preprocessing data ...\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11818.88 MB\n",
            "\tTrain Data (Original)  Memory Usage: 0.01 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\t\tFitting CategoryFeatureGenerator...\n",
            "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
            "\t\tFitting DatetimeFeatureGenerator...\n",
            "\t\tFitting TextSpecialFeatureGenerator...\n",
            "\t\t\tFitting BinnedFeatureGenerator...\n",
            "\t\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\t\tFitting TextNgramFeatureGenerator...\n",
            "\t\t\tFitting CountVectorizer for text features: ['E']\n",
            "\t\t\tCountVectorizer fit with vocabulary size = 4\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tStage 5 Generators:\n",
            "\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('category', [])     : 1 | ['D']\n",
            "\t\t('datetime', [])     : 1 | ['C']\n",
            "\t\t('float', [])        : 1 | ['A']\n",
            "\t\t('int', [])          : 1 | ['B']\n",
            "\t\t('object', ['text']) : 1 | ['E']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('category', [])                    : 1 | ['D']\n",
            "\t\t('category', ['text_as_category'])  : 1 | ['E']\n",
            "\t\t('float', [])                       : 1 | ['A']\n",
            "\t\t('int', [])                         : 1 | ['B']\n",
            "\t\t('int', ['binned', 'text_special']) : 2 | ['E.char_count', 'E.symbol_ratio. ']\n",
            "\t\t('int', ['datetime_as_int'])        : 5 | ['C', 'C.year', 'C.month', 'C.day', 'C.dayofweek']\n",
            "\t\t('int', ['text_ngram'])             : 5 | ['__nlp__.abc', '__nlp__.ef', '__nlp__.ghi', '__nlp__.jkl', '__nlp__._total_']\n",
            "\t0.4s = Fit runtime\n",
            "\t5 features in original data used to generate 16 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 0.01 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.5s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
            "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 80, Val Rows: 20\n",
            "User-specified model hyperparameters to be fit:\n",
            "{\n",
            "\t'GBM': [{}],\n",
            "}\n",
            "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: LightGBM ... Training model for up to 59.50s of the 59.50s of remaining time.\n",
            "\tFitting with cpus=1, gpus=0, mem=0.0/11.2 GB\n",
            "\t-60.7795\t = Validation score   (-root_mean_squared_error)\n",
            "\t14.68s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ... Training model for up to 59.50s of the 44.80s of remaining time.\n",
            "\tEnsemble Weights: {'LightGBM': 1.0}\n",
            "\t-60.7795\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.0s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 15.24s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 6199.5 rows/s (20 batch size)\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/content/AutogluonModels/ag-20251026_192142\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✓ Model training complete!\n"
          ]
        }
      ],
      "source": [
        "# Combine features and labels\n",
        "df = pd.concat([dfx, dfy], axis=1)\n",
        "\n",
        "# Create a fresh feature generator for training\n",
        "auto_ml_pipeline_feature_generator = AutoMLPipelineFeatureGenerator()\n",
        "\n",
        "# Create and train predictor\n",
        "print(\"=\"*70)\n",
        "print(\"TRAINING MODEL WITH AUTOGLUON\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "predictor = TabularPredictor(label='label')\n",
        "predictor.fit(\n",
        "    df,\n",
        "    hyperparameters={'GBM': {}},\n",
        "    feature_generator=auto_ml_pipeline_feature_generator,\n",
        "    time_limit=60  # 60 seconds training limit\n",
        ")\n",
        "\n",
        "print(\"\\n✓ Model training complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "check_unique",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5979dacf-885e-4fcc-bd8a-c4ca95cb13b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of unique values in column B: 5\n",
            "Unique values: [np.int64(-2), np.int64(-1), np.int64(0), np.int64(1), np.int64(2)]\n",
            "\n",
            "✓ Column B marked as categorical\n",
            "\n",
            "New data type for B: category\n"
          ]
        }
      ],
      "source": [
        "print(\"Number of unique values in column B:\", len(set(dfx['B'])))\n",
        "print(\"Unique values:\", sorted(dfx['B'].unique()))\n",
        "\n",
        "# Even though B has few values, it wasn't detected as categorical\n",
        "# Let's explicitly mark it as categorical\n",
        "dfx[\"B\"] = dfx[\"B\"].astype(\"category\")\n",
        "\n",
        "print(\"\\n✓ Column B marked as categorical\")\n",
        "print(\"\\nNew data type for B:\", dfx['B'].dtype)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "retransform",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc12c9e4-9c52-47f1-e618-77de707bdccb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11302.20 MB\n",
            "\tTrain Data (Original)  Memory Usage: 0.01 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\t\tFitting CategoryFeatureGenerator...\n",
            "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
            "\t\tFitting DatetimeFeatureGenerator...\n",
            "\t\tFitting TextSpecialFeatureGenerator...\n",
            "\t\t\tFitting BinnedFeatureGenerator...\n",
            "\t\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\t\tFitting TextNgramFeatureGenerator...\n",
            "\t\t\tFitting CountVectorizer for text features: ['E']\n",
            "\t\t\tCountVectorizer fit with vocabulary size = 4\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tStage 5 Generators:\n",
            "\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('category', [])     : 2 | ['B', 'D']\n",
            "\t\t('datetime', [])     : 1 | ['C']\n",
            "\t\t('float', [])        : 1 | ['A']\n",
            "\t\t('object', ['text']) : 1 | ['E']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('category', [])                    : 2 | ['B', 'D']\n",
            "\t\t('category', ['text_as_category'])  : 1 | ['E']\n",
            "\t\t('float', [])                       : 1 | ['A']\n",
            "\t\t('int', ['binned', 'text_special']) : 2 | ['E.char_count', 'E.symbol_ratio. ']\n",
            "\t\t('int', ['datetime_as_int'])        : 5 | ['C', 'C.year', 'C.month', 'C.day', 'C.dayofweek']\n",
            "\t\t('int', ['text_ngram'])             : 5 | ['__nlp__.abc', '__nlp__.ef', '__nlp__.ghi', '__nlp__.jkl', '__nlp__._total_']\n",
            "\t0.1s = Fit runtime\n",
            "\t5 features in original data used to generate 16 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 0.01 MB (0.0% of available memory)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "TRANSFORMED DATA (with B as categorical)\n",
            "======================================================================\n",
            "          A  B  D    E                   C  C.year  C.month  C.day  \\\n",
            "0 -0.545774  1  3  NaN  946684800000000000    2000        1      1   \n",
            "1 -0.468674  1  2  NaN  946771200000000000    2000        1      2   \n",
            "2  1.767960  1  0  NaN  946598400000000000    1999       12     31   \n",
            "3 -0.118771  2  3    4  946684800000000000    2000        1      1   \n",
            "4  0.630196  1  1  NaN  946598400000000000    1999       12     31   \n",
            "5  0.035360  1  3  NaN  946684800000000000    2000        1      1   \n",
            "6  0.602319  1  0  NaN  946771200000000000    2000        1      2   \n",
            "7 -0.200758  1  1  NaN  946684800000000000    2000        1      1   \n",
            "8 -0.822467  1  0  NaN  946684800000000000    2000        1      1   \n",
            "9 -2.060141  1  3    5  946771200000000000    2000        1      2   \n",
            "\n",
            "   C.dayofweek  E.char_count  E.symbol_ratio.   __nlp__.abc  __nlp__.ef  \\\n",
            "0            5             5                 2            0           0   \n",
            "1            6             6                 1            1           1   \n",
            "2            4             4                 3            0           1   \n",
            "3            5             3                 4            1           2   \n",
            "4            4             2                 5            0           1   \n",
            "5            5             7                 0            1           0   \n",
            "6            6             5                 2            1           2   \n",
            "7            5             3                 4            0           0   \n",
            "8            5             3                 4            0           0   \n",
            "9            6             5                 2            1           0   \n",
            "\n",
            "   __nlp__.ghi  __nlp__.jkl  __nlp__._total_  \n",
            "0            1            2                2  \n",
            "1            1            1                4  \n",
            "2            1            1                3  \n",
            "3            0            0                2  \n",
            "4            1            0                2  \n",
            "5            1            2                3  \n",
            "6            1            0                3  \n",
            "7            1            1                2  \n",
            "8            1            1                2  \n",
            "9            2            0                2  \n"
          ]
        }
      ],
      "source": [
        "# Re-transform with B as categorical\n",
        "auto_ml_pipeline_feature_generator = AutoMLPipelineFeatureGenerator()\n",
        "transformed_data = auto_ml_pipeline_feature_generator.fit_transform(X=dfx)\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"TRANSFORMED DATA (with B as categorical)\")\n",
        "print(\"=\"*70)\n",
        "print(transformed_data.head(10))\n",
        "\n",
        "# Notice that B is now recognized as categorical in the feature types output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "add_missing",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0729ef49-896c-4880-f931-f4ab312936e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "DATASET WITH MISSING VALUES\n",
            "======================================================================\n",
            "\n",
            "First 5 rows (note the first row is all NaN):\n",
            "          A    B          C    D               E\n",
            "0       NaN  NaN        NaT  NaN             NaN\n",
            "1 -0.468674    0 2000-01-02    x  jkl ef abc ghi\n",
            "2  1.767960    0 1999-12-31    v    d ef ghi jkl\n",
            "3 -0.118771    1 2000-01-01    y     d abc ef ef\n",
            "4  0.630196    0 1999-12-31    w      d ghi ef d\n"
          ]
        }
      ],
      "source": [
        "# Set first row to NaN\n",
        "dfx.iloc[0] = np.nan\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"DATASET WITH MISSING VALUES\")\n",
        "print(\"=\"*70)\n",
        "print(\"\\nFirst 5 rows (note the first row is all NaN):\")\n",
        "print(dfx.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "transform_missing",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f75e545d-bad4-4f39-82c8-5c15d0910c4b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11301.71 MB\n",
            "\tTrain Data (Original)  Memory Usage: 0.01 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\t\tFitting CategoryFeatureGenerator...\n",
            "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
            "\t\tFitting DatetimeFeatureGenerator...\n",
            "\t\tFitting TextSpecialFeatureGenerator...\n",
            "\t\t\tFitting BinnedFeatureGenerator...\n",
            "\t\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\t\tFitting TextNgramFeatureGenerator...\n",
            "\t\t\tFitting CountVectorizer for text features: ['E']\n",
            "\t\t\tCountVectorizer fit with vocabulary size = 4\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tStage 5 Generators:\n",
            "\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('category', [])     : 2 | ['B', 'D']\n",
            "\t\t('datetime', [])     : 1 | ['C']\n",
            "\t\t('float', [])        : 1 | ['A']\n",
            "\t\t('object', ['text']) : 1 | ['E']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('category', [])                    : 2 | ['B', 'D']\n",
            "\t\t('category', ['text_as_category'])  : 1 | ['E']\n",
            "\t\t('float', [])                       : 1 | ['A']\n",
            "\t\t('int', ['binned', 'text_special']) : 3 | ['E.char_count', 'E.word_count', 'E.symbol_ratio. ']\n",
            "\t\t('int', ['datetime_as_int'])        : 5 | ['C', 'C.year', 'C.month', 'C.day', 'C.dayofweek']\n",
            "\t\t('int', ['text_ngram'])             : 5 | ['__nlp__.abc', '__nlp__.ef', '__nlp__.ghi', '__nlp__.jkl', '__nlp__._total_']\n",
            "\t5.2s = Fit runtime\n",
            "\t5 features in original data used to generate 17 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 0.01 MB (0.0% of available memory)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "TRANSFORMED DATA WITH MISSING VALUES\n",
            "======================================================================\n",
            "\n",
            "First 5 rows:\n",
            "          A    B    D    E                   C  C.year  C.month  C.day  \\\n",
            "0       NaN  NaN  NaN  NaN  946687418181818240    2000        1      1   \n",
            "1 -0.468674    1    2  NaN  946771200000000000    2000        1      2   \n",
            "2  1.767960    1    0  NaN  946598400000000000    1999       12     31   \n",
            "3 -0.118771    2    3    4  946684800000000000    2000        1      1   \n",
            "4  0.630196    1    1  NaN  946598400000000000    1999       12     31   \n",
            "\n",
            "   C.dayofweek  E.char_count  E.word_count  E.symbol_ratio.   __nlp__.abc  \\\n",
            "0            5             0             0                 0            0   \n",
            "1            6             7             1                 2            1   \n",
            "2            4             5             1                 4            0   \n",
            "3            5             4             1                 5            1   \n",
            "4            4             3             1                 6            0   \n",
            "\n",
            "   __nlp__.ef  __nlp__.ghi  __nlp__.jkl  __nlp__._total_  \n",
            "0           0            0            0                0  \n",
            "1           1            1            1                4  \n",
            "2           1            1            1                3  \n",
            "3           2            0            0                2  \n",
            "4           1            1            0                2  \n",
            "\n",
            "======================================================================\n",
            "MISSING VALUE HANDLING OBSERVATIONS\n",
            "======================================================================\n",
            "\n",
            "Key observations:\n",
            "1. Float column 'A': NaN retained\n",
            "2. Integer column 'B': NaN retained\n",
            "3. Categorical column 'D': NaN retained\n",
            "4. Text column 'E': NaN retained, text features set to 0\n",
            "5. Datetime column 'C': NaN replaced with MEAN of non-NaN values!\n",
            "   - This is a special behavior for datetime columns\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Transform with missing values\n",
        "auto_ml_pipeline_feature_generator = AutoMLPipelineFeatureGenerator()\n",
        "transformed_with_missing = auto_ml_pipeline_feature_generator.fit_transform(X=dfx)\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"TRANSFORMED DATA WITH MISSING VALUES\")\n",
        "print(\"=\"*70)\n",
        "print(\"\\nFirst 5 rows:\")\n",
        "print(transformed_with_missing.head())\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"MISSING VALUE HANDLING OBSERVATIONS\")\n",
        "print(\"=\"*70)\n",
        "print(\"\"\"\n",
        "Key observations:\n",
        "1. Float column 'A': NaN retained\n",
        "2. Integer column 'B': NaN retained\n",
        "3. Categorical column 'D': NaN retained\n",
        "4. Text column 'E': NaN retained, text features set to 0\n",
        "5. Datetime column 'C': NaN replaced with MEAN of non-NaN values!\n",
        "   - This is a special behavior for datetime columns\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "custom_pipeline",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1493dc91-179a-4046-f55a-25adf31863c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fitting PipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11273.13 MB\n",
            "\tTrain Data (Original)  Memory Usage: 0.01 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting CategoryFeatureGenerator...\n",
            "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tStage 5 Generators:\n",
            "\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\tUnused Original Features (Count: 1): ['C']\n",
            "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
            "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
            "\t\tThese features do not need to be present at inference time.\n",
            "\t\t('datetime', []) : 1 | ['C']\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('category', [])     : 1 | ['D']\n",
            "\t\t('float', [])        : 1 | ['A']\n",
            "\t\t('int', [])          : 1 | ['B']\n",
            "\t\t('object', ['text']) : 1 | ['E']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('category', [])                   : 1 | ['D']\n",
            "\t\t('category', ['text_as_category']) : 1 | ['E']\n",
            "\t\t('float', [])                      : 1 | ['A']\n",
            "\t\t('int', [])                        : 1 | ['B']\n",
            "\t0.1s = Fit runtime\n",
            "\t4 features in original data used to generate 4 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 0.00 MB (0.0% of available memory)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "CUSTOM FEATURE ENGINEERING PIPELINE\n",
            "======================================================================\n",
            "\n",
            "Parameters:\n",
            "  - Maximum categories: 10\n",
            "  - Only keep numeric and categorical features\n",
            "  - No datetime or text processing\n",
            "\n",
            "======================================================================\n",
            "CUSTOM TRANSFORMED DATA\n",
            "======================================================================\n",
            "\n",
            "First 10 rows:\n",
            "   D    E         A  B\n",
            "0  3    0 -0.545774  0\n",
            "1  2  NaN -0.468674  0\n",
            "2  0  NaN  1.767960  0\n",
            "3  3  NaN -0.118771  1\n",
            "4  1  NaN  0.630196  0\n",
            "5  3  NaN  0.035360  0\n",
            "6  0  NaN  0.602319  0\n",
            "7  1  NaN -0.200758  0\n",
            "8  0  NaN -0.822467  0\n",
            "9  3  NaN -2.060141  0\n",
            "\n",
            "======================================================================\n",
            "Note: Datetime column 'C' was dropped because we only kept numeric and categorical features!\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "# Recreate data without missing values for this example\n",
        "x, y = make_regression(n_samples=100, n_features=5, n_targets=1, random_state=1)\n",
        "dfx = pd.DataFrame(x, columns=['A', 'B', 'C', 'D', 'E'])\n",
        "dfx['B'] = (dfx['B']).astype(int)\n",
        "dfx['C'] = datetime(2000, 1, 1) + pd.to_timedelta(dfx['C'].astype(int), unit='D')\n",
        "dfx['D'] = pd.cut(dfx['D'] * 10, [-np.inf, -5, 0, 5, np.inf], labels=['v', 'w', 'x', 'y'])\n",
        "dfx['E'] = pd.Series([\n",
        "    ' '.join(random.choice([\"abc\", \"d\", \"ef\", \"ghi\", \"jkl\"]) for i in range(4))\n",
        "    for j in range(100)\n",
        "])\n",
        "\n",
        "# Create custom pipeline\n",
        "custom_pipeline = PipelineFeatureGenerator(\n",
        "    generators=[[\n",
        "        CategoryFeatureGenerator(maximum_num_cat=10),  # Limit to 10 categories max\n",
        "        IdentityFeatureGenerator(infer_features_in_args=dict(valid_raw_types=[R_INT, R_FLOAT])),\n",
        "    ]]\n",
        ")\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"CUSTOM FEATURE ENGINEERING PIPELINE\")\n",
        "print(\"=\"*70)\n",
        "print(\"\\nParameters:\")\n",
        "print(\"  - Maximum categories: 10\")\n",
        "print(\"  - Only keep numeric and categorical features\")\n",
        "print(\"  - No datetime or text processing\")\n",
        "\n",
        "# Transform with custom pipeline\n",
        "custom_transformed = custom_pipeline.fit_transform(X=dfx)\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"CUSTOM TRANSFORMED DATA\")\n",
        "print(\"=\"*70)\n",
        "print(\"\\nFirst 10 rows:\")\n",
        "print(custom_transformed.head(10))\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"Note: Datetime column 'C' was dropped because we only kept numeric and categorical features!\")\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "load_real_data",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "838fdfec-0bb1-4fa3-b4de-a8dac1d15868"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loaded data from: https://autogluon.s3.amazonaws.com/datasets/Inc/train.csv | Columns = 15 / 15 | Rows = 39073 -> 39073\n",
            "Loaded data from: https://autogluon.s3.amazonaws.com/datasets/Inc/test.csv | Columns = 15 / 15 | Rows = 9769 -> 9769\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "ADULT INCOME DATASET\n",
            "======================================================================\n",
            "\n",
            "Train data shape: (39073, 15)\n",
            "Test data shape: (9769, 15)\n",
            "\n",
            "First 5 rows:\n",
            "   age   workclass  fnlwgt   education  education-num       marital-status  \\\n",
            "0   25     Private  178478   Bachelors             13        Never-married   \n",
            "1   23   State-gov   61743     5th-6th              3        Never-married   \n",
            "2   46     Private  376789     HS-grad              9        Never-married   \n",
            "3   55           ?  200235     HS-grad              9   Married-civ-spouse   \n",
            "4   36     Private  224541     7th-8th              4   Married-civ-spouse   \n",
            "\n",
            "           occupation    relationship    race      sex  capital-gain  \\\n",
            "0        Tech-support       Own-child   White   Female             0   \n",
            "1    Transport-moving   Not-in-family   White     Male             0   \n",
            "2       Other-service   Not-in-family   White     Male             0   \n",
            "3                   ?         Husband   White     Male             0   \n",
            "4   Handlers-cleaners         Husband   White     Male             0   \n",
            "\n",
            "   capital-loss  hours-per-week  native-country   class  \n",
            "0             0              40   United-States   <=50K  \n",
            "1             0              35   United-States   <=50K  \n",
            "2             0              15   United-States   <=50K  \n",
            "3             0              50   United-States    >50K  \n",
            "4             0              40     El-Salvador   <=50K  \n",
            "\n",
            "======================================================================\n",
            "COLUMN INFORMATION\n",
            "======================================================================\n",
            "\n",
            "Column types:\n",
            "age                int64\n",
            "workclass         object\n",
            "fnlwgt             int64\n",
            "education         object\n",
            "education-num      int64\n",
            "marital-status    object\n",
            "occupation        object\n",
            "relationship      object\n",
            "race              object\n",
            "sex               object\n",
            "capital-gain       int64\n",
            "capital-loss       int64\n",
            "hours-per-week     int64\n",
            "native-country    object\n",
            "class             object\n",
            "dtype: object\n"
          ]
        }
      ],
      "source": [
        "# Load a real dataset from AutoGluon\n",
        "from autogluon.tabular import TabularDataset\n",
        "\n",
        "# Load adult income dataset\n",
        "train_data = TabularDataset('https://autogluon.s3.amazonaws.com/datasets/Inc/train.csv')\n",
        "test_data = TabularDataset('https://autogluon.s3.amazonaws.com/datasets/Inc/test.csv')\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"ADULT INCOME DATASET\")\n",
        "print(\"=\"*70)\n",
        "print(f\"\\nTrain data shape: {train_data.shape}\")\n",
        "print(f\"Test data shape: {test_data.shape}\")\n",
        "\n",
        "print(\"\\nFirst 5 rows:\")\n",
        "print(train_data.head())\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"COLUMN INFORMATION\")\n",
        "print(\"=\"*70)\n",
        "print(\"\\nColumn types:\")\n",
        "print(train_data.dtypes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "train_real_data",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac614c08-62b0-4671-c3e6-85c5cb015d2b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Verbosity: 2 (Standard Logging)\n",
            "=================== System Info ===================\n",
            "AutoGluon Version:  1.4.0\n",
            "Python Version:     3.12.12\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP Thu Oct  2 10:42:05 UTC 2025\n",
            "CPU Count:          2\n",
            "Memory Avail:       10.99 GB / 12.67 GB (86.7%)\n",
            "Disk Space Avail:   61.60 GB / 107.72 GB (57.2%)\n",
            "===================================================\n",
            "Presets specified: ['medium_quality']\n",
            "Using hyperparameters preset: hyperparameters='default'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "TRAINING ON REAL DATASET\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Beginning AutoGluon training ... Time limit = 120s\n",
            "AutoGluon will save models to \"/content/ag_models\"\n",
            "Train Data Rows:    39073\n",
            "Train Data Columns: 14\n",
            "Label Column:       class\n",
            "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
            "\t2 unique label values:  [' <=50K', ' >50K']\n",
            "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
            "Problem Type:       binary\n",
            "Preprocessing data ...\n",
            "Selected class <--> label mapping:  class 1 =  >50K, class 0 =  <=50K\n",
            "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive ( >50K) vs negative ( <=50K) class.\n",
            "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11274.83 MB\n",
            "\tTrain Data (Original)  Memory Usage: 19.48 MB (0.2% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\t\tFitting CategoryFeatureGenerator...\n",
            "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tStage 5 Generators:\n",
            "\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('int', [])    : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
            "\t\t('object', []) : 8 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('category', [])  : 7 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\n",
            "\t\t('int', [])       : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
            "\t\t('int', ['bool']) : 1 | ['sex']\n",
            "\t0.4s = Fit runtime\n",
            "\t14 features in original data used to generate 14 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 2.09 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.5s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.0639828014229775, Train Rows: 36573, Val Rows: 2500\n",
            "User-specified model hyperparameters to be fit:\n",
            "{\n",
            "\t'NN_TORCH': [{}],\n",
            "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
            "\t'CAT': [{}],\n",
            "\t'XGB': [{}],\n",
            "\t'FASTAI': [{}],\n",
            "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "}\n",
            "Fitting 11 L1 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: LightGBMXT ... Training model for up to 119.50s of the 119.50s of remaining time.\n",
            "\tFitting with cpus=1, gpus=0, mem=0.0/11.0 GB\n",
            "\t0.8792\t = Validation score   (accuracy)\n",
            "\t3.07s\t = Training   runtime\n",
            "\t0.11s\t = Validation runtime\n",
            "Fitting model: LightGBM ... Training model for up to 116.26s of the 116.26s of remaining time.\n",
            "\tFitting with cpus=1, gpus=0, mem=0.0/11.0 GB\n",
            "\t0.8824\t = Validation score   (accuracy)\n",
            "\t1.8s\t = Training   runtime\n",
            "\t0.07s\t = Validation runtime\n",
            "Fitting model: RandomForestGini ... Training model for up to 114.37s of the 114.37s of remaining time.\n",
            "\tFitting with cpus=2, gpus=0, mem=0.0/11.0 GB\n",
            "\t0.8612\t = Validation score   (accuracy)\n",
            "\t12.87s\t = Training   runtime\n",
            "\t0.2s\t = Validation runtime\n",
            "Fitting model: RandomForestEntr ... Training model for up to 100.85s of the 100.85s of remaining time.\n",
            "\tFitting with cpus=2, gpus=0, mem=0.0/10.8 GB\n",
            "\t0.8584\t = Validation score   (accuracy)\n",
            "\t13.83s\t = Training   runtime\n",
            "\t0.21s\t = Validation runtime\n",
            "Fitting model: CatBoost ... Training model for up to 86.36s of the 86.36s of remaining time.\n",
            "\tFitting with cpus=1, gpus=0\n",
            "\t0.8836\t = Validation score   (accuracy)\n",
            "\t42.73s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: ExtraTreesGini ... Training model for up to 43.61s of the 43.61s of remaining time.\n",
            "\tFitting with cpus=2, gpus=0, mem=0.0/10.6 GB\n",
            "\t0.8528\t = Validation score   (accuracy)\n",
            "\t9.57s\t = Training   runtime\n",
            "\t0.24s\t = Validation runtime\n",
            "Fitting model: ExtraTreesEntr ... Training model for up to 32.94s of the 32.94s of remaining time.\n",
            "\tFitting with cpus=2, gpus=0, mem=0.0/10.4 GB\n",
            "\t0.8524\t = Validation score   (accuracy)\n",
            "\t8.94s\t = Training   runtime\n",
            "\t0.24s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI ... Training model for up to 22.92s of the 22.92s of remaining time.\n",
            "\tFitting with cpus=1, gpus=0, mem=0.0/10.4 GB\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 11)\n",
            "\t0.8572\t = Validation score   (accuracy)\n",
            "\t22.76s\t = Training   runtime\n",
            "\t0.04s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ... Training model for up to 119.50s of the 0.08s of remaining time.\n",
            "\tEnsemble Weights: {'LightGBM': 0.5, 'LightGBMXT': 0.333, 'CatBoost': 0.167}\n",
            "\t0.886\t = Validation score   (accuracy)\n",
            "\t0.11s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 120.11s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 13213.6 rows/s (2500 batch size)\n",
            "Disabling decision threshold calibration for metric `accuracy` due to having fewer than 10000 rows of validation data for calibration, to avoid overfitting (2500 rows).\n",
            "\t`accuracy` is generally not improved through threshold calibration. Force calibration via specifying `calibrate_decision_threshold=True`.\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/content/ag_models\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✓ Training complete!\n",
            "\n",
            "======================================================================\n",
            "MODEL EVALUATION\n",
            "======================================================================\n",
            "\n",
            "Test accuracy: {'accuracy': 0.8756269833145665, 'balanced_accuracy': np.float64(0.7992916389378104), 'mcc': np.float64(0.639682445135486), 'roc_auc': np.float64(0.9309127368696652), 'f1': 0.7139157052036732, 'precision': 0.7858994297563504, 'recall': 0.6540120793787748}\n"
          ]
        }
      ],
      "source": [
        "# Train a model with automatic feature engineering\n",
        "print(\"=\"*70)\n",
        "print(\"TRAINING ON REAL DATASET\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "label = 'class'  # Target column\n",
        "predictor = TabularPredictor(label=label, path='ag_models')\n",
        "\n",
        "predictor.fit(\n",
        "    train_data,\n",
        "    time_limit=120,  # 2 minutes\n",
        "    presets='medium_quality',\n",
        ")\n",
        "\n",
        "print(\"\\n✓ Training complete!\")\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"MODEL EVALUATION\")\n",
        "print(\"=\"*70)\n",
        "performance = predictor.evaluate(test_data)\n",
        "print(f\"\\nTest accuracy: {performance}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "feature_importance",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "67e3e807-d64a-48f6-dbc4-799a6a52340d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Computing feature importance via permutation shuffling for 14 features using 5000 rows with 5 shuffle sets...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "FEATURE IMPORTANCE\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t29.7s\t= Expected runtime (5.94s per shuffle set)\n",
            "\t30.25s\t= Actual runtime (Completed 5 of 5 shuffle sets)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Top 15 most important features:\n",
            "                importance    stddev   p_value  n  p99_high   p99_low\n",
            "capital-gain       0.04556  0.004075  0.000008  5  0.053951  0.037169\n",
            "occupation         0.01768  0.003180  0.000120  5  0.024228  0.011132\n",
            "age                0.01652  0.004242  0.000479  5  0.025254  0.007786\n",
            "marital-status     0.01468  0.003714  0.000452  5  0.022327  0.007033\n",
            "relationship       0.01420  0.004370  0.000953  5  0.023199  0.005201\n",
            "education-num      0.01244  0.003948  0.001070  5  0.020569  0.004311\n",
            "capital-loss       0.01168  0.001635  0.000045  5  0.015046  0.008314\n",
            "hours-per-week     0.00640  0.002417  0.002037  5  0.011376  0.001424\n",
            "workclass          0.00288  0.002500  0.030809  5  0.008028 -0.002268\n",
            "fnlwgt             0.00220  0.001631  0.019654  5  0.005558 -0.001158\n",
            "education          0.00184  0.002913  0.115372  5  0.007839 -0.004159\n",
            "native-country     0.00120  0.001010  0.028288  5  0.003280 -0.000880\n",
            "sex                0.00088  0.001016  0.062404  5  0.002972 -0.001212\n",
            "race               0.00084  0.001785  0.176081  5  0.004516 -0.002836\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x800 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Check feature importance\n",
        "print(\"=\"*70)\n",
        "print(\"FEATURE IMPORTANCE\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "feature_importance = predictor.feature_importance(test_data)\n",
        "print(\"\\nTop 15 most important features:\")\n",
        "print(feature_importance.head(15))\n",
        "\n",
        "# Visualize feature importance\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "top_features = feature_importance.head(15)\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.barh(range(len(top_features)), top_features['importance'])\n",
        "plt.yticks(range(len(top_features)), top_features.index) # Corrected to use the DataFrame index\n",
        "plt.xlabel('Importance')\n",
        "plt.title('Top 15 Feature Importance')\n",
        "plt.gca().invert_yaxis()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "leaderboard",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5db4b230-83ef-40ec-ae94-9559e4958460"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "MODEL LEADERBOARD\n",
            "======================================================================\n",
            "                 model  score_test  score_val eval_metric  pred_time_test  \\\n",
            "0             CatBoost    0.875627     0.8836    accuracy        0.031558   \n",
            "1  WeightedEnsemble_L2    0.875627     0.8860    accuracy        0.776734   \n",
            "2             LightGBM    0.873477     0.8824    accuracy        0.274650   \n",
            "3           LightGBMXT    0.871430     0.8792    accuracy        0.467707   \n",
            "4     RandomForestGini    0.859351     0.8612    accuracy        0.808148   \n",
            "5     RandomForestEntr    0.857611     0.8584    accuracy        0.729632   \n",
            "6      NeuralNetFastAI    0.856280     0.8572    accuracy        0.232495   \n",
            "7       ExtraTreesGini    0.853414     0.8528    accuracy        0.874923   \n",
            "8       ExtraTreesEntr    0.850650     0.8524    accuracy        1.276814   \n",
            "\n",
            "   pred_time_val   fit_time  pred_time_test_marginal  pred_time_val_marginal  \\\n",
            "0       0.010037  42.728891                 0.031558                0.010037   \n",
            "1       0.189200  47.702439                 0.002818                0.000977   \n",
            "2       0.065139   1.796480                 0.274650                0.065139   \n",
            "3       0.113047   3.065258                 0.467707                0.113047   \n",
            "4       0.197296  12.868917                 0.808148                0.197296   \n",
            "5       0.208035  13.825129                 0.729632                0.208035   \n",
            "6       0.043354  22.756996                 0.232495                0.043354   \n",
            "7       0.240278   9.570532                 0.874923                0.240278   \n",
            "8       0.235438   8.939693                 1.276814                0.235438   \n",
            "\n",
            "   fit_time_marginal  stack_level  can_infer  fit_order  \n",
            "0          42.728891            1       True          5  \n",
            "1           0.111811            2       True          9  \n",
            "2           1.796480            1       True          2  \n",
            "3           3.065258            1       True          1  \n",
            "4          12.868917            1       True          3  \n",
            "5          13.825129            1       True          4  \n",
            "6          22.756996            1       True          8  \n",
            "7           9.570532            1       True          6  \n",
            "8           8.939693            1       True          7  \n"
          ]
        }
      ],
      "source": [
        "# View model leaderboard\n",
        "print(\"=\"*70)\n",
        "print(\"MODEL LEADERBOARD\")\n",
        "print(\"=\"*70)\n",
        "leaderboard = predictor.leaderboard(test_data)\n",
        "print(leaderboard)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}